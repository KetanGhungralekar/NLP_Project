{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2734496,
          "sourceType": "datasetVersion",
          "datasetId": 1654566
        },
        {
          "sourceId": 11294753,
          "sourceType": "datasetVersion",
          "datasetId": 7062438
        },
        {
          "sourceId": 11359085,
          "sourceType": "datasetVersion",
          "datasetId": 7109217
        },
        {
          "sourceId": 11359565,
          "sourceType": "datasetVersion",
          "datasetId": 7109591
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Abstractive_summarisation_model",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "gowrishankarp_newspaper_text_summarization_cnn_dailymail_path = kagglehub.dataset_download('gowrishankarp/newspaper-text-summarization-cnn-dailymail')\n",
        "ketanghungralekar_model123_path = kagglehub.dataset_download('ketanghungralekar/model123')\n",
        "deathsinger205_pkl1234556_path = kagglehub.dataset_download('deathsinger205/pkl1234556')\n",
        "vmit24_pklw123344_path = kagglehub.dataset_download('vmit24/pklw123344')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Kr-YDBbmzyj6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style='text-align: center;text-color:blue;'><strong>Sequnce to Sequence modelling</strong></h1>\n",
        "<h2 style='text-align: center;text-color:blue;'>With Teacher Forcing and Attention Mechanism</h2>\n",
        "\n",
        "This notebook explores the implementation of a Sequence-to-Sequence (seq2seq) model with attention and teacher forcing for the task of text summarization.\n",
        "\n",
        "Background:\n",
        "+ **Text Summarization**: The process of condensing a longer piece of text (e.g., an article, document) into a shorter version while preserving the most important information.\n",
        "+ **Seq2seq Models**: A class of neural networks designed to handle sequence-to-sequence tasks, such as machine translation, text summarization, and question answering. They consist of an encoder that processes the input sequence and a decoder that generates the output sequence.  \n",
        "+ **Attention Mechanism**: A key component in modern seq2seq models that allows the decoder to focus on different parts of the input sequence when generating each output token. This improves the model's ability to capture long-range dependencies and produce more accurate translations or summaries.  (My notebook : https://www.kaggle.com/code/divyanshvishwkarma/seq2seq-with-attention-mechanism)\n",
        "+ **Teacher Forcing**: A training technique where the ground truth output tokens are fed as input to the decoder during training. This helps stabilize training and improve the quality of the generated output, especially in the early stages of training. (My notebook : https://www.kaggle.com/code/divyanshvishwkarma/teacher-forcing-in-seq2seq-tensorflow-and-keras)\n",
        "\n"
      ],
      "metadata": {
        "id": "gzahGwApzyj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style='text-align:center;'>Seq2Seq models</h2>\n",
        "Seq2Seq models are a type of neural network architecture designed to handle tasks involving sequential data, such as machine translation and text summarization. They consist of two main components: an encoder, which processes the input sequence and creates a context vector, and a decoder, which generates the output sequence based on the context vector. Seq2Seq models have revolutionized many NLP tasks by effectively transforming one sequence into another.\n",
        "<p style='text-align:center;'><img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Ismhi-muID5ooWf3ZIQFFg.png'></p>"
      ],
      "metadata": {
        "id": "ypaGHNskzyj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>"
      ],
      "metadata": {
        "id": "r0Dnu3aEzyj9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style='text-align:center;'>Importing Libraries</h2>"
      ],
      "metadata": {
        "id": "iZQRPBoOzyj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers as L\n",
        "from tensorflow.keras import models as M\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:31:12.872605Z",
          "iopub.execute_input": "2025-04-11T06:31:12.872874Z",
          "iopub.status.idle": "2025-04-11T06:31:27.657797Z",
          "shell.execute_reply.started": "2025-04-11T06:31:12.872846Z",
          "shell.execute_reply": "2025-04-11T06:31:27.656923Z"
        },
        "id": "vJgWWOGuzyj9",
        "outputId": "d36e8263-5102-4e0d-ac01-338cbdf69675"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-04-11 06:31:14.544031: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744353074.745003      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744353074.804322      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Filtering Training Data Based on Length Constraints</span></strong></p>\n",
        "\n",
        "To prevent **GPU resource exhaustion errors on Kaggle**, the training data is filtered before model training:\n",
        "\n",
        "- Articles and summaries that exceed predefined limits are removed:\n",
        "  - `TEXT_SIZE` for the input article length\n",
        "  - `SUMM_SIZE` for the target summary length\n",
        "- This ensures efficient usage of limited GPU memory during training.\n",
        "\n",
        "Filtering helps keep the dataset manageable while still retaining high-quality training examples.\n"
      ],
      "metadata": {
        "id": "1TZqdP8Xzyj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_SIZE = 1600\n",
        "SUMM_SIZE = 500"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:31:34.600358Z",
          "iopub.execute_input": "2025-04-11T06:31:34.600987Z",
          "iopub.status.idle": "2025-04-11T06:31:34.604728Z",
          "shell.execute_reply.started": "2025-04-11T06:31:34.600963Z",
          "shell.execute_reply": "2025-04-11T06:31:34.603847Z"
        },
        "id": "AZC33Uv2zyj-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>"
      ],
      "metadata": {
        "id": "v8kcQiZTzyj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 style='text-align:center'>About the data</h3>"
      ],
      "metadata": {
        "id": "dLOCkEPfzyj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style='text-align:center'>Link : <a>https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail</a> <br><br>The CNN / DailyMail Dataset is an English-language dataset containing just over 300k unique news articles as written by journalists at CNN and the Daily Mail. The current version supports both extractive and abstractive summarization, though the original version was created for machine reading and comprehension and abstractive question answering. </p>"
      ],
      "metadata": {
        "id": "bRbGYWZSzyj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:39:36.260682Z",
          "iopub.execute_input": "2025-04-10T18:39:36.261389Z",
          "iopub.status.idle": "2025-04-10T18:40:04.265641Z",
          "shell.execute_reply.started": "2025-04-10T18:39:36.261356Z",
          "shell.execute_reply": "2025-04-10T18:40:04.264943Z"
        },
        "trusted": true,
        "id": "WGbWbI5zzyj-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train['article'].apply(lambda x: len(x)<TEXT_SIZE)]\n",
        "train = train[train['highlights'].apply(lambda x: len(x)<SUMM_SIZE)]\n",
        "len(train)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:08.882914Z",
          "iopub.execute_input": "2025-04-10T18:40:08.883235Z",
          "iopub.status.idle": "2025-04-10T18:40:09.241595Z",
          "shell.execute_reply.started": "2025-04-10T18:40:08.883216Z",
          "shell.execute_reply": "2025-04-10T18:40:09.240897Z"
        },
        "trusted": true,
        "id": "J3b0QdaLzyj_",
        "outputId": "2860eb52-efe7-4bd2-929f-37c8f3ae3ea2"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "18775"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.reset_index().drop(['index','id'], axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:14.977789Z",
          "iopub.execute_input": "2025-04-10T18:40:14.978548Z",
          "iopub.status.idle": "2025-04-10T18:40:14.99671Z",
          "shell.execute_reply.started": "2025-04-10T18:40:14.978522Z",
          "shell.execute_reply": "2025-04-10T18:40:14.995614Z"
        },
        "trusted": true,
        "id": "FjOYmTHizyj_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:43:08.379466Z",
          "iopub.status.busy": "2025-04-06T07:43:08.378801Z",
          "iopub.status.idle": "2025-04-06T07:43:08.391222Z",
          "shell.execute_reply": "2025-04-06T07:43:08.390354Z",
          "shell.execute_reply.started": "2025-04-06T07:43:08.379432Z"
        },
        "trusted": true,
        "id": "ufi3q0w0zyj_",
        "outputId": "4cd22696-3791-49a8-b9fd-d29165736b9e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n",
              "      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kabul, Afghanistan (CNN) -- China's top securi...</td>\n",
              "      <td>China's top security official visited Afghanis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(CNN) -- Virgin, a leading branded venture cap...</td>\n",
              "      <td>The Virgin Group was founded by Richard Branso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>By . Chris Pleasance . Police are hunting for ...</td>\n",
              "      <td>Two men filmed taking iPad from canoe rental o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Baghdad (CNN) -- Radical Iraqi cleric Muqtada ...</td>\n",
              "      <td>Muqtada al-Sadr has been in Iran since 2007 .\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PUBLISHED: . 07:04 EST, 9 January 2014 . | . U...</td>\n",
              "      <td>Zhu Sanni, 23, had been left alone at home for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kabul, Afghanistan (CNN) -- Thousands of bottl...</td>\n",
              "      <td>Official: Bottles are almost exclusively from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(CNN) -- Tour de France race director Christia...</td>\n",
              "      <td>The 2013 Tour de France will start from the Fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(CNN) -- Hundreds filed by a casket on Sunday ...</td>\n",
              "      <td>Wes Leonard collapsed after scoring a winning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Earlier this season I picked Thierry Henry as ...</td>\n",
              "      <td>Sportsmail columnist Martin Keown was honoured...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article  \\\n",
              "0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n",
              "1  Kabul, Afghanistan (CNN) -- China's top securi...   \n",
              "2  (CNN) -- Virgin, a leading branded venture cap...   \n",
              "3  By . Chris Pleasance . Police are hunting for ...   \n",
              "4  Baghdad (CNN) -- Radical Iraqi cleric Muqtada ...   \n",
              "5  PUBLISHED: . 07:04 EST, 9 January 2014 . | . U...   \n",
              "6  Kabul, Afghanistan (CNN) -- Thousands of bottl...   \n",
              "7  (CNN) -- Tour de France race director Christia...   \n",
              "8  (CNN) -- Hundreds filed by a casket on Sunday ...   \n",
              "9  Earlier this season I picked Thierry Henry as ...   \n",
              "\n",
              "                                          highlights  \n",
              "0  Bishop John Folda, of North Dakota, is taking ...  \n",
              "1  China's top security official visited Afghanis...  \n",
              "2  The Virgin Group was founded by Richard Branso...  \n",
              "3  Two men filmed taking iPad from canoe rental o...  \n",
              "4  Muqtada al-Sadr has been in Iran since 2007 .\\...  \n",
              "5  Zhu Sanni, 23, had been left alone at home for...  \n",
              "6  Official: Bottles are almost exclusively from ...  \n",
              "7  The 2013 Tour de France will start from the Fr...  \n",
              "8  Wes Leonard collapsed after scoring a winning ...  \n",
              "9  Sportsmail columnist Martin Keown was honoured...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h3 style='text-align:center'>Example text from the dataset</h3>"
      ],
      "metadata": {
        "id": "olQhFuqzzyj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['article'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T15:55:00.772968Z",
          "iopub.status.busy": "2025-04-05T15:55:00.772652Z",
          "iopub.status.idle": "2025-04-05T15:55:00.779459Z",
          "shell.execute_reply": "2025-04-05T15:55:00.77849Z",
          "shell.execute_reply.started": "2025-04-05T15:55:00.77294Z"
        },
        "trusted": true,
        "id": "VPmYaOV0zyj_",
        "outputId": "0c3bc280-e5f4-4865-a9ff-84e18e1ec101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train['highlights'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T15:55:00.780915Z",
          "iopub.status.busy": "2025-04-05T15:55:00.780613Z",
          "iopub.status.idle": "2025-04-05T15:55:00.789888Z",
          "shell.execute_reply": "2025-04-05T15:55:00.789169Z",
          "shell.execute_reply.started": "2025-04-05T15:55:00.780887Z"
        },
        "trusted": true,
        "id": "lwqYw1Ozzyj_",
        "outputId": "6297fb54-dfe1-4752-e96b-6f53b1ddbfa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\\nHe contracted the infection through contaminated food in Italy .\\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>"
      ],
      "metadata": {
        "id": "4glW1EqAzyj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style='text-align:center;'><strong>Preprocessing data</strong></h2>"
      ],
      "metadata": {
        "id": "kd10LrXxzyj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style='text-align:center;'>\n",
        "The initial step involves converting the input and target text into sequences of tokens, which can be individual words or sub-word units. This is typically achieved through tokenization techniques. To ensure uniform input shapes for the model, the sequences are then padded with special tokens (e.g., &lt;PAD&gt;) to achieve equal lengths. Finally, to provide clear boundaries for the model, special start (&lt;START&gt;) and end (&lt;END&gt;) tokens are added to the beginning and end of the target sequences, respectively. This preprocessed data is then ready to be fed into the seq2seq model for training and inference.\n",
        "</p>"
      ],
      "metadata": {
        "id": "hafed7_izyj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<p style='text-align:center;'><img src='https://miro.medium.com/v2/resize:fit:1400/1*IFpVaaEdNfEkIPA3BaIhuw.png'></p>"
      ],
      "metadata": {
        "id": "QP-9fTNHzyj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = np.array(train.iloc[:, 0:1]), np.array(train.iloc[:,1:2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:22.88706Z",
          "iopub.execute_input": "2025-04-10T18:40:22.887355Z",
          "iopub.status.idle": "2025-04-10T18:40:22.894027Z",
          "shell.execute_reply.started": "2025-04-10T18:40:22.887335Z",
          "shell.execute_reply": "2025-04-10T18:40:22.893283Z"
        },
        "trusted": true,
        "id": "MR5mela8zyj_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = X.reshape(X.shape[0]), y.reshape(y.shape[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:25.73698Z",
          "iopub.execute_input": "2025-04-10T18:40:25.737696Z",
          "iopub.status.idle": "2025-04-10T18:40:25.742111Z",
          "shell.execute_reply.started": "2025-04-10T18:40:25.737672Z",
          "shell.execute_reply": "2025-04-10T18:40:25.741148Z"
        },
        "trusted": true,
        "id": "JvVr_ckzzyj_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "### Adding \"start\" and \"end\" token to the label datapoints"
      ],
      "metadata": {
        "id": "7EVXsd3wzykA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START = '<start>'\n",
        "END = '<end>'\n",
        "PAD = '<PAD>'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:28.839987Z",
          "iopub.execute_input": "2025-04-10T18:40:28.840592Z",
          "iopub.status.idle": "2025-04-10T18:40:28.844491Z",
          "shell.execute_reply.started": "2025-04-10T18:40:28.840571Z",
          "shell.execute_reply": "2025-04-10T18:40:28.843849Z"
        },
        "trusted": true,
        "id": "BgBMopFjzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y = [f\"{START} {text} {END}\" for text in y]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:39.828899Z",
          "iopub.execute_input": "2025-04-10T18:40:39.829535Z",
          "iopub.status.idle": "2025-04-10T18:40:39.842865Z",
          "shell.execute_reply.started": "2025-04-10T18:40:39.829509Z",
          "shell.execute_reply": "2025-04-10T18:40:39.842228Z"
        },
        "trusted": true,
        "id": "HLo5Hr4LzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h4 style='text-align:center;'>Taking out a few data points for infernce</h4>"
      ],
      "metadata": {
        "id": "xMDuT53ozykA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = -10\n",
        "X_test, y_test = X[size:], y[size:]\n",
        "X, y = X[:size], y[:size]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:40:33.529288Z",
          "iopub.execute_input": "2025-04-10T18:40:33.529887Z",
          "iopub.status.idle": "2025-04-10T18:40:33.534413Z",
          "shell.execute_reply.started": "2025-04-10T18:40:33.529865Z",
          "shell.execute_reply": "2025-04-10T18:40:33.533693Z"
        },
        "trusted": true,
        "id": "yvtjBB4zzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h4 style='text-align:center;'>Preparing Tokenizer and finding vocabulary size</h4>"
      ],
      "metadata": {
        "id": "OcUKGPXqzykA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e_tk, d_tk = Tokenizer(), Tokenizer()\n",
        "e_tk.fit_on_texts(X)\n",
        "d_tk.fit_on_texts(y)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:43:30.136818Z",
          "iopub.status.busy": "2025-04-06T07:43:30.136483Z",
          "iopub.status.idle": "2025-04-06T07:43:33.95398Z",
          "shell.execute_reply": "2025-04-06T07:43:33.953301Z",
          "shell.execute_reply.started": "2025-04-06T07:43:30.136787Z"
        },
        "trusted": true,
        "id": "37TWpH78zykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = d_tk.word_index.get(START.strip('<>'))\n",
        "end_id = d_tk.word_index.get(END.strip('<>'))\n",
        "pad_id = 0"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:43:46.424419Z",
          "iopub.status.busy": "2025-04-06T07:43:46.424058Z",
          "iopub.status.idle": "2025-04-06T07:43:46.428599Z",
          "shell.execute_reply": "2025-04-06T07:43:46.427648Z",
          "shell.execute_reply.started": "2025-04-06T07:43:46.424388Z"
        },
        "trusted": true,
        "id": "ewwEv-M-zykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "in_vocab_size, out_vocab_size = len(e_tk.word_index) + 1, len(d_tk.word_index) + 1\n",
        "in_vocab_size, out_vocab_size"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:43:49.609215Z",
          "iopub.status.busy": "2025-04-06T07:43:49.608601Z",
          "iopub.status.idle": "2025-04-06T07:43:49.615067Z",
          "shell.execute_reply": "2025-04-06T07:43:49.614065Z",
          "shell.execute_reply.started": "2025-04-06T07:43:49.60915Z"
        },
        "trusted": true,
        "id": "3XwDKF4-zykA",
        "outputId": "7b0353b3-5f2b-4dcb-ee0a-029bddeb0192"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(91127, 41940)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h4 style='text-align:center;'>Converting text to sequences, padding them and finalizing the three series (enc_inputs, dec_inputs, targets) <br> analogous to (X, dec_target_input, y)</h4>"
      ],
      "metadata": {
        "id": "UqVpYlvjzykA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs = e_tk.texts_to_sequences(X)\n",
        "targets = d_tk.texts_to_sequences(y)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:43:56.760335Z",
          "iopub.status.busy": "2025-04-06T07:43:56.759767Z",
          "iopub.status.idle": "2025-04-06T07:43:59.513525Z",
          "shell.execute_reply": "2025-04-06T07:43:59.512676Z",
          "shell.execute_reply.started": "2025-04-06T07:43:56.760301Z"
        },
        "trusted": true,
        "id": "DwkSvFlPzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style='text-align:center;'><img src='https://miro.medium.com/v2/resize:fit:1400/1*yM9GYw49kIFf3bKp2Eg2AQ.png' width=50%></p>"
      ],
      "metadata": {
        "id": "7qtHbF4tzykA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "find_len = lambda x : max([len(seq) for seq in x])+1\n",
        "input_seq_len, output_seq_len = find_len(enc_inputs), find_len(targets)\n",
        "input_seq_len, output_seq_len"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:06.355618Z",
          "iopub.status.busy": "2025-04-06T07:44:06.355275Z",
          "iopub.status.idle": "2025-04-06T07:44:06.368591Z",
          "shell.execute_reply": "2025-04-06T07:44:06.367738Z",
          "shell.execute_reply.started": "2025-04-06T07:44:06.355588Z"
        },
        "trusted": true,
        "id": "ieh0Mxu3zykA",
        "outputId": "b8699daf-38e8-4245-e905-fa5ba8ceb591"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(329, 95)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "enc_inputs =np.array(pad_sequences(enc_inputs, padding='post', truncating='post', maxlen = input_seq_len))"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:09.743454Z",
          "iopub.status.busy": "2025-04-06T07:44:09.742765Z",
          "iopub.status.idle": "2025-04-06T07:44:09.970912Z",
          "shell.execute_reply": "2025-04-06T07:44:09.969937Z",
          "shell.execute_reply.started": "2025-04-06T07:44:09.74342Z"
        },
        "trusted": true,
        "id": "eSduzvrmzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "targets = pad_sequences(targets, padding='post', truncating='post', maxlen = output_seq_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:12.170927Z",
          "iopub.status.busy": "2025-04-06T07:44:12.170043Z",
          "iopub.status.idle": "2025-04-06T07:44:12.245857Z",
          "shell.execute_reply": "2025-04-06T07:44:12.244919Z",
          "shell.execute_reply.started": "2025-04-06T07:44:12.170886Z"
        },
        "trusted": true,
        "id": "WxaK7VUZzykA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dec_inputs = np.array(targets[:, :-1])\n",
        "targets =  np.array(targets[:, 1:])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:15.314098Z",
          "iopub.status.busy": "2025-04-06T07:44:15.313548Z",
          "iopub.status.idle": "2025-04-06T07:44:15.324026Z",
          "shell.execute_reply": "2025-04-06T07:44:15.323138Z",
          "shell.execute_reply.started": "2025-04-06T07:44:15.314064Z"
        },
        "trusted": true,
        "id": "kvV_a2A4zykE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h4 style='text-align:center;'>Dimensions of parameter</h4>"
      ],
      "metadata": {
        "id": "fNbH5ozCzykE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "in_vocab_size, out_vocab_size, input_seq_len, output_seq_len"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:17.879617Z",
          "iopub.status.busy": "2025-04-06T07:44:17.879036Z",
          "iopub.status.idle": "2025-04-06T07:44:17.885197Z",
          "shell.execute_reply": "2025-04-06T07:44:17.884288Z",
          "shell.execute_reply.started": "2025-04-06T07:44:17.87958Z"
        },
        "trusted": true,
        "id": "2bO3_3_kzykE",
        "outputId": "85cd0820-0e60-4fcb-8d13-8aad7eeec2cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(91127, 41940, 329, 95)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h2 style='text-align:center;'><strong>\n",
        "    Attention Mechanism\n",
        "    </strong> (Bahdanau Attention)</h2>\n",
        "\n",
        "Bahdanau attention, also known as additive attention, is a mechanism designed to improve the performance of sequence-to-sequence models. It works by enabling the model to focus on specific parts of the input sequence when generating each part of the output sequence.\n",
        "\n",
        "<p>The decoder hidden state $s_{t}$ (query) at the $t^{th}$ timestep is passed to all encoder hidden states (keys : $h_{1}$, $h_{2}$,..., $h_{T}$) to calculate scores.\n",
        "The attention mechanism ensures that the decoder focuses on the most relevant parts of the input (as represented by the keys) when generating the next output token.</p>"
      ],
      "metadata": {
        "id": "TGdMgDGrzykE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style='text-align:center;'><img src='https://machinelearningmastery.com/wp-content/uploads/2021/09/bahdanau_1.png' width=50%></p>"
      ],
      "metadata": {
        "id": "4SEquavAzykE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(L.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = L.Dense(units)\n",
        "        self.W2 = L.Dense(units)\n",
        "        self.V = L.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # query - shape == (batch_size, hidden_size) -> decoder hidden state at the current timestep\n",
        "        # values - shape == (batch_size, max_len/timesteps, hidden_size) -> encoder outputs (all timesteps)\n",
        "        # here, hidden_size = units, max_len = timesteps\n",
        "        query = tf.expand_dims(query, axis = 1)                # (batch_size, 1, hidden_size)\n",
        "        score = self.V(tf.nn.tanh(self.W1(query) + self.W2(values)))  # (batch_size, timesteps, 1)\n",
        "        attention_weight = tf.nn.softmax(score, axis = 1)      # (batch_size, timesteps, 1)\n",
        "        context = attention_weight*values                      # (batch_size, timesteps, hidden_size)\n",
        "        context_vector = tf.reduce_sum(context, axis = 1)      # (batch_size, hidden_size)\n",
        "        return context_vector, attention_weight"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:32:14.764816Z",
          "iopub.execute_input": "2025-04-11T06:32:14.765602Z",
          "iopub.status.idle": "2025-04-11T06:32:14.77144Z",
          "shell.execute_reply.started": "2025-04-11T06:32:14.765579Z",
          "shell.execute_reply": "2025-04-11T06:32:14.770621Z"
        },
        "trusted": true,
        "id": "xvnxoSTxzykE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h2 style='text-align:center;'><strong>\n",
        "    Model Defination\n",
        "    </strong></h2>\n",
        "\n",
        "+ Teacher Forcing is implemented in the  **train_step**  method where we use the actual target sequence as input to the decoder during training.\n",
        "+ The model uses separate Encoder and Decoder classes for better organization.\n",
        "+ A generate method is included for inference, which uses the model's own predictions rather than teacher forcing.\n",
        "+ The architecture uses LSTM cells, but you can easily modify it to use GRU or other RNN cells."
      ],
      "metadata": {
        "id": "PaHNoGikzykE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "S6cRUZYWzykE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(L.Layer):\n",
        "    def __init__(self, in_vocab, embedding_dim, hidden_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embed = L.Embedding(in_vocab, embedding_dim)       # (batch_size, seq_length) -> (batch_size, seq_length, embedding_dim)\n",
        "        self.lstm = L.LSTM(hidden_units, return_sequences=True,return_state = True)   # (batch_size, seq_length, embedding_dim) -> (batch_size, hidden_units)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # input : (batch_size, seq_length)\n",
        "        x = self.embed(inputs)                               # (batch_size, seq_length, embeddign_dim)\n",
        "        enc_out, hidden_state, cell_state = self.lstm(x)     # O/P (batch_size, seq_len, hidden_size)\n",
        "        return enc_out, hidden_state, cell_state"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:32:22.237287Z",
          "iopub.execute_input": "2025-04-11T06:32:22.238051Z",
          "iopub.status.idle": "2025-04-11T06:32:22.244815Z",
          "shell.execute_reply.started": "2025-04-11T06:32:22.238017Z",
          "shell.execute_reply": "2025-04-11T06:32:22.24386Z"
        },
        "trusted": true,
        "id": "F-RHoPlVzykE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "LbwuzXUozykF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(L.Layer):\n",
        "    def __init__(self, out_vocab, embedding_dim, hidden_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embed = L.Embedding(out_vocab, embedding_dim)     # (batch_size, seq_length) -> (batch_size, seq_length, embedding_dim)\n",
        "        self.lstm = L.LSTM(hidden_units, return_sequences = True, return_state = True)  # (batch_size, seq_length, embedding_dim) -> (batch_size, hidden_units)\n",
        "        self.dense = L.Dense(out_vocab, activation='softmax')  # (batch_size, seq_length, hidden_units) -> (batch_size, seq_length, out_vocab)\n",
        "        self.attention = BahdanauAttention(64)\n",
        "\n",
        "    def call(self, inputs, hidden_state, cell_state, enc_output):\n",
        "        # input : (batch_size, 1)\n",
        "        x = self.embed(inputs)                                 # (batch_size, 1, embedding_dim)\n",
        "        states = [hidden_state, cell_state]\n",
        "        context, attention_weights = self.attention(query = hidden_state, values = enc_output)\n",
        "        dec_out, hidden_state, cell_state = self.lstm(x, initial_state=states)  # O/P : (batch_size, 1, hidden_units)\n",
        "        dec_out = tf.squeeze(dec_out, axis=1)                  # (batch_size, hidden_units)\n",
        "        # context = tf.expand_dims(context, axis=1)              # (batch_size, 1, embedding_dim)\n",
        "        inputs = tf.concat([context, dec_out], axis=-1)        # (batch_size, 1, embedding_dim + enc_units)\n",
        "        out = self.dense(inputs)                               # (batch_size, 1, out_vocab)\n",
        "        return out, hidden_state, cell_state"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:32:26.839403Z",
          "iopub.execute_input": "2025-04-11T06:32:26.839719Z",
          "iopub.status.idle": "2025-04-11T06:32:26.846692Z",
          "shell.execute_reply.started": "2025-04-11T06:32:26.839696Z",
          "shell.execute_reply": "2025-04-11T06:32:26.845643Z"
        },
        "trusted": true,
        "id": "ew05hN0vzykF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>"
      ],
      "metadata": {
        "id": "j18vFn86zykF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <h2 style='text-align:center;'><strong>Teacher Forcing</strong></h2>\n",
        "<p style='text-align:center;'>Instead of passing the output of the current timestep as the input to the next\n",
        "During training, teacher forcing provides the model with the ground truth (actual) output from the training data instead of feeding the model's own previous output as input. Teacher Forcing makes convergence faster during training especially in the starting epochs.</p>\n",
        "<a href=\"https://ibb.co/LzR9pnD\"><p style='text-align:center;'><img src=\"https://i.ibb.co/VW9MB20/Your-paragraph-text.png\" alt=\"Your-paragraph-text\" border=\"0\"></p></a>"
      ],
      "metadata": {
        "id": "S1f0w7T8zykF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Note:\n",
        "<p> This model defination contains extra elements like the serializable decorator and the two config methods, they are optional and can be skipped without any issues. However they are required if you need to save the model in .keras format.</p>"
      ],
      "metadata": {
        "id": "uRIVi7jgzykF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable(package=\"Custom\", name=\"Seq2Seq\")\n",
        "class Seq2Seq(M.Model):\n",
        "\n",
        "    def __init__(self, in_vocab, out_vocab, embedding_dim, hidden_units, end_token):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.in_vocab = in_vocab\n",
        "        self.out_vocab = out_vocab\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_units = hidden_units\n",
        "\n",
        "        self.encoder = Encoder(in_vocab, embedding_dim, hidden_units)\n",
        "        self.decoder = Decoder(out_vocab, embedding_dim, hidden_units)\n",
        "        self.end_token = end_token\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, inputs):\n",
        "        (enc_inputs, dec_inputs), targets = inputs         # (batch_size, seq_length)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_out, hidden_state, cell_state = self.encoder(enc_inputs)           # (batch_size, hidden_units)\n",
        "            seq_len = dec_inputs.shape[1]\n",
        "            dec_out = tf.TensorArray(tf.float32, seq_len)  # (batch_size, seq_len, target_vocab_size)\n",
        "            mask = tf.TensorArray(tf.bool, size=seq_len)\n",
        "            for timestep in tf.range(seq_len):\n",
        "                timestep_input = dec_inputs[:, timestep:timestep+1]       # (batch_size, 1)\n",
        "                timestep_output, hidden_state, cell_state = self.decoder(timestep_input, hidden_state, cell_state, enc_out)   # timestep_output -> # (batch_size, 1, hidden_units)\n",
        "                dec_out = dec_out.write(timestep, timestep_output)\n",
        "                is_end = tf.equal(targets[:, timestep], self.end_token)  # Creating mask based on whether end token is encountered\n",
        "                mask = mask.write(timestep, tf.logical_not(is_end))\n",
        "            dec_out = tf.transpose(dec_out.stack(), [1, 0, 2])\n",
        "            sequence_mask = tf.transpose(mask.stack(), [1, 0])\n",
        "            loss = self.compiled_loss(targets, dec_out, sample_weight=tf.cast(sequence_mask, tf.float32))\n",
        "        variables = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        self.compiled_metrics.update_state(targets, dec_out) # Update metrics\n",
        "        return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training=False):\n",
        "        enc_inputs, dec_inputs = inputs\n",
        "        enc_out, hidden_state, cell_state = self.encoder(enc_inputs)   # (batch_size, hidden_units)\n",
        "        seq_len = tf.shape(dec_inputs)[1]\n",
        "        dec_out = tf.TensorArray(tf.float32, seq_len)  # (batch_size, seq_len, target_vocab_size)\n",
        "        for timestep in tf.range(seq_len):\n",
        "            timestep_input = dec_inputs[:, timestep:timestep+1]       # (batch_size, 1)\n",
        "            timestep_output, hidden_state, cell_state = self.decoder(timestep_input, hidden_state, cell_state, enc_out)   # timestep_output -> # (batch_size, 1, hidden_units)\n",
        "            dec_out = dec_out.write(timestep, timestep_output)\n",
        "        return tf.transpose(dec_out.stack(), [1, 0, 2])\n",
        "\n",
        "\n",
        "    def generate(self, enc_inputs, max_len, start, end):\n",
        "        enc_out, hidden_state, cell_state = self.encoder(enc_inputs)\n",
        "        dec_in = tf.expand_dims([start], 0)              # To get from int -> (1,1) tensor\n",
        "        result = []\n",
        "        for _ in range(max_len):\n",
        "            prediction_logits, hidden_state, cell_state = self.decoder(dec_in, hidden_state, cell_state, enc_out) # (1, 1, hidden_units)\n",
        "            prediction = tf.argmax(prediction_logits, axis=-1)        # return token ID (int)\n",
        "            if prediction == end:\n",
        "                break\n",
        "            result.append(prediction.numpy())\n",
        "            dec_in = tf.expand_dims(prediction, 0)\n",
        "        return result\n",
        "\n",
        "\n",
        "    # def get_config(self):\n",
        "    #     config = super(Seq2Seq, self).get_config()\n",
        "    #     config.update({\n",
        "    #           'in_vocab': self.in_vocab,\n",
        "    #           'out_vocab': self.out_vocab,\n",
        "    #           'embedding_dim': self.embedding_dim,\n",
        "    #           'hidden_units': self.hidden_units\n",
        "    #       })\n",
        "    #     return config\n",
        "\n",
        "    # @classmethod\n",
        "    # def from_config(cls, config):\n",
        "    #     return cls(\n",
        "    #         in_vocab=config['in_vocab'],\n",
        "    #         out_vocab=config['out_vocab'],\n",
        "    #         embedding_dim=config['embedding_dim'],\n",
        "    #         hidden_units=config['hidden_units']\n",
        "    #     )\n",
        "    def get_config(self):\n",
        "        config = super(Seq2Seq, self).get_config()\n",
        "        config.update({\n",
        "            'in_vocab': self.in_vocab,\n",
        "            'out_vocab': self.out_vocab,\n",
        "            'embedding_dim': self.embedding_dim,\n",
        "            'hidden_units': self.hidden_units,\n",
        "            'end_token': self.end_token  # üõ†Ô∏è include this!\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        end_token = config.get('end_token', 0)  # üõ†Ô∏è set a default or handle gracefully\n",
        "        return cls(\n",
        "            in_vocab=config['in_vocab'],\n",
        "            out_vocab=config['out_vocab'],\n",
        "            embedding_dim=config['embedding_dim'],\n",
        "            hidden_units=config['hidden_units'],\n",
        "            end_token=end_token\n",
        "        )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:32:36.976764Z",
          "iopub.execute_input": "2025-04-11T06:32:36.977073Z",
          "iopub.status.idle": "2025-04-11T06:32:36.994917Z",
          "shell.execute_reply.started": "2025-04-11T06:32:36.977051Z",
          "shell.execute_reply": "2025-04-11T06:32:36.994013Z"
        },
        "trusted": true,
        "id": "L7rMSIXOzykF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h2 style='text-align:center;'><strong>Model Instance and Training</strong></h2>\n",
        "<p style='text-align:center;'>The model was trained over 40 epochs of training, hyperparameters are 512 embedding dimension and 512 LSTM units in both encoder and decoder.</p>\n",
        "<p style='text-align:center;'>This Notebook may not contain the model training output as it was saved and we again tried to train but due to resource exhaustion errors for bigger text size you can see training cells don't have output </p>"
      ],
      "metadata": {
        "id": "3Atzod4EzykF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Seq2Seq(in_vocab=in_vocab_size, out_vocab=out_vocab_size, embedding_dim=1024, hidden_units=512, end_token=end_id)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T15:55:08.835177Z",
          "iopub.status.busy": "2025-04-05T15:55:08.83487Z",
          "iopub.status.idle": "2025-04-05T15:55:09.722304Z",
          "shell.execute_reply": "2025-04-05T15:55:09.721529Z",
          "shell.execute_reply.started": "2025-04-05T15:55:08.83515Z"
        },
        "trusted": true,
        "id": "AUr-DlyvzykF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T15:55:09.723505Z",
          "iopub.status.busy": "2025-04-05T15:55:09.723254Z",
          "iopub.status.idle": "2025-04-05T15:55:09.743818Z",
          "shell.execute_reply": "2025-04-05T15:55:09.7429Z",
          "shell.execute_reply.started": "2025-04-05T15:55:09.723479Z"
        },
        "trusted": true,
        "id": "sQMPgk0gzykF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((enc_inputs, dec_inputs), targets, batch_size=32, epochs=1, validation_split=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T15:55:09.745667Z",
          "iopub.status.busy": "2025-04-05T15:55:09.74502Z",
          "iopub.status.idle": "2025-04-05T16:03:22.43619Z",
          "shell.execute_reply": "2025-04-05T16:03:22.435277Z",
          "shell.execute_reply.started": "2025-04-05T15:55:09.745635Z"
        },
        "trusted": true,
        "id": "QonGk0j0zykF",
        "outputId": "74ad26e0-8537-4c12-8e45-ba12d14823eb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:603: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight)`.\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:578: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m470/470\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 1s/step - accuracy: 0.5928 - loss: 2.3844e-05 - val_accuracy: 0.6292 - val_loss: 2.9843\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78dc2135e5f0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((enc_inputs, dec_inputs), targets, batch_size=32, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-05T16:03:22.437684Z",
          "iopub.status.busy": "2025-04-05T16:03:22.437381Z"
        },
        "trusted": true,
        "id": "V_vYMNAezykG",
        "outputId": "60d91062-57a2-431a-97ab-bd25ac9ac8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m470/470\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 1s/step - accuracy: 0.6321 - loss: 2.3844e-05 - val_accuracy: 0.6478 - val_loss: 2.7503\n",
            "Epoch 2/20\n",
            "\u001b[1m470/470\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 1s/step - accuracy: 0.6496 - loss: 2.3844e-05 - val_accuracy: 0.6552 - val_loss: 2.6526\n",
            "Epoch 3/20\n",
            "\u001b[1m284/470\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m2:58\u001b[0m 961ms/step - accuracy: 0.6636 - loss: 2.3844e-05"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((enc_inputs, dec_inputs), targets, batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "gTKfodPCzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit((enc_inputs, dec_inputs), targets, batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "TvqeFCzvzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Saving all required files after loading the model</span></strong></p>\n",
        "\n",
        "After training the model with attention and teacher forcing, the following components are saved to ensure reproducibility and smooth inference:\n",
        "\n",
        "- The trained **Keras model** is saved, which includes both the architecture and the learned weights.\n",
        "- **Encoder and decoder tokenizers** are saved using `pickle`, preserving the vocabulary and tokenization logic.\n",
        "- A **metadata dictionary** is saved containing:\n",
        "  - The word-to-index mapping (`word_dict`)\n",
        "  - Special tokens like `start_id` and `end_id`\n",
        "  - Sequence lengths for both input and output (`input_seq_len` and `output_seq_len`)\n",
        "\n",
        "These files together enable the model to be reloaded and used for prediction without the need for retraining or redefining preprocessing steps.\n"
      ],
      "metadata": {
        "id": "TdYHBt--zykG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Attention_Model_(teacher_forcing).keras')"
      ],
      "metadata": {
        "trusted": true,
        "id": "O-cn7fYrzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"e_tk.pkl\", \"wb\") as f:\n",
        "    pickle.dump(e_tk, f)\n",
        "\n",
        "with open(\"d_tk.pkl\", \"wb\") as f:\n",
        "    pickle.dump(d_tk, f)\n",
        "\n",
        "metadata = {\n",
        "    \"word_dict\": word_dict,\n",
        "    \"start_id\": start_id,\n",
        "    \"end_id\": end_id,\n",
        "    \"input_seq_len\": input_seq_len,\n",
        "    \"output_seq_len\": output_seq_len\n",
        "}\n",
        "\n",
        "with open(\"metadata.pkl\", \"wb\") as f:\n",
        "    pickle.dump(metadata, f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "T8u0TE6YzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h3 style='text-align:center;'><strong>Model Inference</strong></h3>\n",
        "<p style='text-align:center;'>\n",
        "With the required saved model and associated files (such as encoder/decoder tokenizers and metadata), the cells under this section can be executed to perform inference or evaluate the model on test data <strong>without retraining the model</strong>. This setup enables quick generation of summaries and computation of evaluation metrics like ROUGE directly.\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "reHfMfCyzykG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word_dict = {v : k for k,v in d_tk.word_index.items()}"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-06T07:44:44.750566Z",
          "iopub.status.busy": "2025-04-06T07:44:44.750227Z",
          "iopub.status.idle": "2025-04-06T07:44:44.761106Z",
          "shell.execute_reply": "2025-04-06T07:44:44.760308Z",
          "shell.execute_reply.started": "2025-04-06T07:44:44.750537Z"
        },
        "trusted": true,
        "id": "b1sN9L_MzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Loading the Trained Model for Inference</span></strong></p>\n",
        "\n",
        "The trained attention-based Seq2Seq model is loaded using Keras for performing inference on new data.\n",
        "\n",
        "- The model was saved after training and is now reloaded using `load_model()`.\n",
        "- Since a custom model class (`Seq2Seq`) was used during training, it must be specified in the `custom_objects` argument to ensure proper reconstruction.\n",
        "- This step restores the trained model's architecture and learned weights, making it ready for inference without retraining.\n"
      ],
      "metadata": {
        "id": "c8--R8yHzykG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"/kaggle/input/model123/Attention_Model_(teacher_forcing).keras\", custom_objects={\"Seq2Seq\": Seq2Seq})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:32:50.844132Z",
          "iopub.execute_input": "2025-04-11T06:32:50.84494Z",
          "iopub.status.idle": "2025-04-11T06:33:18.83164Z",
          "shell.execute_reply.started": "2025-04-11T06:32:50.844913Z",
          "shell.execute_reply": "2025-04-11T06:33:18.830959Z"
        },
        "trusted": true,
        "id": "ct2ZDnJBzykG",
        "outputId": "f3d190c2-26fc-4a44-ea6f-8502e92bab84"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1744353172.051433      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Loading Tokenizers and Metadata for Inference</span></strong></p>\n",
        "\n",
        "To perform inference using the trained model, it's essential to load the same preprocessing components used during training:\n",
        "\n",
        "- **Encoder and decoder tokenizers** are loaded using `pickle`. These tokenizers preserve the vocabulary mappings required for encoding input sequences and decoding outputs.\n",
        "- A **metadata file** is also loaded, which contains:\n",
        "  - `word_dict`: Mapping of words to indices\n",
        "  - `start_id` and `end_id`: Special tokens used to denote the beginning and end of sequences\n",
        "  - `input_seq_len` and `output_seq_len`: Sequence lengths used during training\n",
        "\n",
        "Loading these components ensures that the input data is tokenized and padded exactly as it was during training, which is crucial for accurate inference.\n"
      ],
      "metadata": {
        "id": "X5nXOcVHzykG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load encoder and decoder tokenizers\n",
        "with open(\"/kaggle/input/pkl1234556/e_tk.pkl\", \"rb\") as f:\n",
        "    e_tk = pickle.load(f)\n",
        "\n",
        "with open(\"/kaggle/input/pkl1234556/d_tk.pkl\", \"rb\") as f:\n",
        "    d_tk = pickle.load(f)\n",
        "\n",
        "# Load metadata (e.g., start/end token IDs, word_dict, etc.)\n",
        "with open(\"/kaggle/input/pkl1234556/metadata.pkl\", \"rb\") as f:\n",
        "    metadata = pickle.load(f)\n",
        "\n",
        "word_dict = metadata[\"word_dict\"]\n",
        "start_id = metadata[\"start_id\"]\n",
        "end_id = metadata[\"end_id\"]\n",
        "input_seq_len = metadata[\"input_seq_len\"]\n",
        "output_seq_len = metadata[\"output_seq_len\"]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:35:51.327171Z",
          "iopub.execute_input": "2025-04-11T06:35:51.32749Z",
          "iopub.status.idle": "2025-04-11T06:35:51.578156Z",
          "shell.execute_reply.started": "2025-04-11T06:35:51.327468Z",
          "shell.execute_reply": "2025-04-11T06:35:51.577531Z"
        },
        "trusted": true,
        "id": "dZakQj1nzykG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Generating Summaries Using the Trained Model</span></strong></p>\n",
        "\n",
        "This function performs **text summarization** using the trained attention-based Seq2Seq model. It takes raw input text and returns a generated summary by following these steps:\n",
        "\n",
        "- **Tokenization & Padding**:  \n",
        "  The input text is first tokenized using the encoder tokenizer and padded to match the input sequence length used during training.\n",
        "\n",
        "- **Prediction**:  \n",
        "  The padded input is passed to the model's `generate` method along with the maximum target length, `start_id`, and `end_id` to produce a sequence of output token IDs.\n",
        "\n",
        "- **Decoding**:  \n",
        "  The generated token IDs are converted back to words using the `word_dict`. Decoding stops upon encountering the `end_id`.\n",
        "\n",
        "- **Return Summary**:  \n",
        "  The decoded words are joined to form the final summarized text, which is returned by the function.\n",
        "\n",
        "This setup ensures that the model can generate summaries for new inputs using the same preprocessing pipeline as in training.\n"
      ],
      "metadata": {
        "id": "bVuT1CZ_zykH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def summarize_text(text, model, source_tokenizer, word_dict,\n",
        "                   start_id, end_id, source_max, target_max):\n",
        "\n",
        "    # Tokenize and pad input\n",
        "    seq = source_tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=source_max, padding='post')\n",
        "\n",
        "    # Generate predictions\n",
        "    model_output = model.generate(seq, target_max, start_id, end_id)\n",
        "\n",
        "    # Decode output tokens to words\n",
        "    output_text = []\n",
        "    for token_id in model_output:\n",
        "        if isinstance(token_id, (list, tuple, np.ndarray)):\n",
        "            token_id = int(token_id[0])\n",
        "        else:\n",
        "            token_id = int(token_id)\n",
        "\n",
        "        if token_id == end_id:\n",
        "            break\n",
        "\n",
        "        word = word_dict.get(token_id, '')\n",
        "        if word:\n",
        "            output_text.append(word)\n",
        "\n",
        "    # print(\"\\nINPUT TEXT:\")\n",
        "    # print(text)\n",
        "    # print(\"\\nGENERATED SUMMARY:\")\n",
        "    # print(' '.join(output_text))\n",
        "\n",
        "    return ' '.join(output_text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-11T06:35:31.782254Z",
          "iopub.execute_input": "2025-04-11T06:35:31.782601Z",
          "iopub.status.idle": "2025-04-11T06:35:31.789506Z",
          "shell.execute_reply.started": "2025-04-11T06:35:31.782576Z",
          "shell.execute_reply": "2025-04-11T06:35:31.788639Z"
        },
        "trusted": true,
        "id": "nA5OIfEczykH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference of a random summary to show"
      ],
      "metadata": {
        "id": "qwb2TfZazykH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Testing the summarize_text Function</span></strong></p>\n",
        "\n",
        "A sample input is used to test the `summarize_text` function and verify that it returns a valid summary.\n",
        "\n",
        "- The function is called with a test input and necessary components.\n",
        "- The generated summary is printed alongside the expected summary for a quick comparison.\n",
        "\n",
        "This simple check ensures the inference pipeline is working as intended.\n"
      ],
      "metadata": {
        "id": "W9dh11VPzykH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = X[0]  # or any custom string\n",
        "summary = summarize_text(\n",
        "    text=example_text,\n",
        "    model=model,\n",
        "    source_tokenizer=e_tk,\n",
        "    word_dict=word_dict,\n",
        "    start_id=start_id,\n",
        "    end_id=end_id,\n",
        "    source_max=input_seq_len,\n",
        "    target_max=output_seq_len\n",
        ")\n",
        "\n",
        "print(\"\\nEXPECTED SUMMARY:\")\n",
        "print(y[0][7:-5])  # trimming <start> and <end> from actual summary if applicable\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-04-10T18:46:52.1959Z",
          "iopub.execute_input": "2025-04-10T18:46:52.196281Z",
          "iopub.status.idle": "2025-04-10T18:46:56.474273Z",
          "shell.execute_reply.started": "2025-04-10T18:46:52.196259Z",
          "shell.execute_reply": "2025-04-10T18:46:56.473345Z"
        },
        "trusted": true,
        "id": "cpGjWC4gzykH",
        "outputId": "f3d4ca9b-8b80-47c1-ee92-7a63076a3ff4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1744310813.219351      95 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nINPUT TEXT:\nBy . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n\nGENERATED SUMMARY:\nbishop john folda of north dakota is taking time off after being diagnosed he contracted the infection through contaminated food in italy church members in fargo grand forks and jamestown could have been exposed to 50 years in extra time the study allows 50 500 people while he was exposed to bounce back in extra time he says he contracted the bishop after his neck that exposed to 50 50 million people were exposed to hospital he contracted the infection in fargo grand forks and jamestown could have been exposed to bounce back in extra\n\nEXPECTED SUMMARY:\n Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\nHe contracted the infection through contaminated food in Italy .\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed . \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Evaluating the Model Using ROUGE Score</span></strong></p>\n",
        "\n",
        "To evaluate the quality of generated summaries, the **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** metric is used.\n",
        "\n",
        "- The generated summaries are compared against the reference (expected) summaries.\n",
        "- ROUGE scores measure the **overlap of n-grams, word sequences, and word pairs** between the two.\n",
        "- Commonly used variants include **ROUGE-1**, **ROUGE-2**, and **ROUGE-L** for unigram, bigram, and longest common subsequence matches.\n",
        "\n",
        "This evaluation provides a quantitative measure of how well the model is performing on the summarization task.\n"
      ],
      "metadata": {
        "id": "aoZen2X4zykH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Loading and Preprocessing Test Data</span></strong></p>\n",
        "\n",
        "The test dataset is loaded to evaluate the performance of the trained model.\n",
        "\n",
        "- The test data is **preprocessed using the same steps** as the training data to maintain consistency.\n",
        "- This includes tokenization, padding, and any necessary formatting.\n",
        "- Ensuring identical preprocessing helps produce reliable and comparable evaluation results.\n"
      ],
      "metadata": {
        "id": "5kA-Kjh_zykH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:33:53.823986Z",
          "iopub.execute_input": "2025-04-11T06:33:53.82467Z",
          "iopub.status.idle": "2025-04-11T06:33:55.009739Z",
          "shell.execute_reply.started": "2025-04-11T06:33:53.824644Z",
          "shell.execute_reply": "2025-04-11T06:33:55.008702Z"
        },
        "id": "OoCEfFCJzykH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Filtering Test Data Based on Length Constraints</span></strong></p>\n",
        "\n",
        "Due to **Kaggle's GPU resource constraints**, unfiltered long sequences can lead to **resource exhaustion errors** during inference.\n",
        "\n",
        "- To prevent this, the test data is filtered similarly to the training data:\n",
        "  - Articles longer than `TEXT_SIZE` and summaries longer than `SUMM_SIZE` are excluded.\n",
        "- This keeps the input within safe bounds for GPU processing and ensures smooth evaluation.\n",
        "\n",
        "Applying these constraints helps avoid crashes while maintaining evaluation consistency.\n"
      ],
      "metadata": {
        "id": "SmBI15r6zykH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test[test['article'].apply(lambda x: len(x)<TEXT_SIZE)]\n",
        "test = test[test['highlights'].apply(lambda x: len(x)<SUMM_SIZE)]\n",
        "len(test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:33:56.331619Z",
          "iopub.execute_input": "2025-04-11T06:33:56.331927Z",
          "iopub.status.idle": "2025-04-11T06:33:56.353503Z",
          "shell.execute_reply.started": "2025-04-11T06:33:56.331905Z",
          "shell.execute_reply": "2025-04-11T06:33:56.35275Z"
        },
        "id": "4comMa5dzykH",
        "outputId": "ca859d8d-6f3d-439e-bdc0-4145c4a04aa6"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "879"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.reset_index().drop(['index','id'], axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:34:01.115104Z",
          "iopub.execute_input": "2025-04-11T06:34:01.115437Z",
          "iopub.status.idle": "2025-04-11T06:34:01.124509Z",
          "shell.execute_reply.started": "2025-04-11T06:34:01.115409Z",
          "shell.execute_reply": "2025-04-11T06:34:01.123742Z"
        },
        "id": "TtoJv_kLzykH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = np.array(test.iloc[:, 0:1]), np.array(test.iloc[:,1:2])\n",
        "X, y = X.reshape(X.shape[0]), y.reshape(y.shape[0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:34:04.470136Z",
          "iopub.execute_input": "2025-04-11T06:34:04.470458Z",
          "iopub.status.idle": "2025-04-11T06:34:04.476515Z",
          "shell.execute_reply.started": "2025-04-11T06:34:04.470438Z",
          "shell.execute_reply": "2025-04-11T06:34:04.475646Z"
        },
        "id": "QKZuFVCyzykI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "START = '<start>'\n",
        "END = '<end>'\n",
        "PAD = '<PAD>'\n",
        "y = [f\"{START} {text} {END}\" for text in y]\n",
        "X_test, y_test = X, y"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:34:07.082288Z",
          "iopub.execute_input": "2025-04-11T06:34:07.083111Z",
          "iopub.status.idle": "2025-04-11T06:34:07.087615Z",
          "shell.execute_reply.started": "2025-04-11T06:34:07.083085Z",
          "shell.execute_reply": "2025-04-11T06:34:07.086705Z"
        },
        "id": "enhD5E-hzykI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\"><strong><span style=\"font-size: 24px;\">Evaluating Model Using ROUGE Scores</span></strong></p>\n",
        "\n",
        "To evaluate the summarization quality of the trained model, **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** metrics are used:\n",
        "\n",
        "- ROUGE-1, ROUGE-2, and ROUGE-L scores are computed to assess the overlap between generated summaries and reference summaries.\n",
        "- The evaluation is performed in two phases:\n",
        "  1. **Initial Evaluation:** On a small subset (first 100 samples) for quick inspection and debugging.\n",
        "  2. **Full Evaluation:** On the entire test set to get a complete performance picture.\n",
        "- Each generated summary is compared against the ground truth using a **stemmer-based ROUGE scorer**, and average F1 scores are calculated.\n",
        "\n",
        "These metrics provide insight into the model's ability to retain important content from the input text.\n"
      ],
      "metadata": {
        "id": "JFiwEXXjzykI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Use only first 100 samples\n",
        "X_subset = X[:100]\n",
        "y_subset = y[:100]\n",
        "\n",
        "# Use last 10 from the subset\n",
        "X_test = X_subset\n",
        "y_test = y_subset\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "avg_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
        "\n",
        "# Generate summaries and calculate scores\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"üîÑ Processing article {i + 1}/{len(X_test)}...\")\n",
        "\n",
        "    summary = summarize_text(\n",
        "        text=X_test[i],\n",
        "        model=model,\n",
        "        source_tokenizer=e_tk,\n",
        "        word_dict=word_dict,\n",
        "        start_id=start_id,\n",
        "        end_id=end_id,\n",
        "        source_max=input_seq_len,\n",
        "        target_max=output_seq_len\n",
        "    )\n",
        "\n",
        "    scores = scorer.score(y_test[i], summary)\n",
        "    for key in scores:\n",
        "        avg_scores[key].append(scores[key].fmeasure)\n",
        "\n",
        "# Compute and print average F1 scores\n",
        "print(\"\\nüìä AVERAGE ROUGE F1 SCORES OVER FIRST 100 SAMPLES:\")\n",
        "for key in avg_scores:\n",
        "    mean_f1 = sum(avg_scores[key]) / len(avg_scores[key])\n",
        "    print(f\"{key.upper()}: {mean_f1:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-10T19:50:58.26449Z",
          "iopub.execute_input": "2025-04-10T19:50:58.265202Z",
          "iopub.status.idle": "2025-04-10T19:53:46.953481Z",
          "shell.execute_reply.started": "2025-04-10T19:50:58.265174Z",
          "shell.execute_reply": "2025-04-10T19:53:46.952861Z"
        },
        "id": "mbAnMRIxzykI",
        "outputId": "6c1e09be-d0f1-42be-8fa1-f6c88f2c528a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üîÑ Processing article 1/100...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1744314660.054336      93 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "üîÑ Processing article 2/100...\nüîÑ Processing article 3/100...\nüîÑ Processing article 4/100...\nüîÑ Processing article 5/100...\nüîÑ Processing article 6/100...\nüîÑ Processing article 7/100...\nüîÑ Processing article 8/100...\nüîÑ Processing article 9/100...\nüîÑ Processing article 10/100...\nüîÑ Processing article 11/100...\nüîÑ Processing article 12/100...\nüîÑ Processing article 13/100...\nüîÑ Processing article 14/100...\nüîÑ Processing article 15/100...\nüîÑ Processing article 16/100...\nüîÑ Processing article 17/100...\nüîÑ Processing article 18/100...\nüîÑ Processing article 19/100...\nüîÑ Processing article 20/100...\nüîÑ Processing article 21/100...\nüîÑ Processing article 22/100...\nüîÑ Processing article 23/100...\nüîÑ Processing article 24/100...\nüîÑ Processing article 25/100...\nüîÑ Processing article 26/100...\nüîÑ Processing article 27/100...\nüîÑ Processing article 28/100...\nüîÑ Processing article 29/100...\nüîÑ Processing article 30/100...\nüîÑ Processing article 31/100...\nüîÑ Processing article 32/100...\nüîÑ Processing article 33/100...\nüîÑ Processing article 34/100...\nüîÑ Processing article 35/100...\nüîÑ Processing article 36/100...\nüîÑ Processing article 37/100...\nüîÑ Processing article 38/100...\nüîÑ Processing article 39/100...\nüîÑ Processing article 40/100...\nüîÑ Processing article 41/100...\nüîÑ Processing article 42/100...\nüîÑ Processing article 43/100...\nüîÑ Processing article 44/100...\nüîÑ Processing article 45/100...\nüîÑ Processing article 46/100...\nüîÑ Processing article 47/100...\nüîÑ Processing article 48/100...\nüîÑ Processing article 49/100...\nüîÑ Processing article 50/100...\nüîÑ Processing article 51/100...\nüîÑ Processing article 52/100...\nüîÑ Processing article 53/100...\nüîÑ Processing article 54/100...\nüîÑ Processing article 55/100...\nüîÑ Processing article 56/100...\nüîÑ Processing article 57/100...\nüîÑ Processing article 58/100...\nüîÑ Processing article 59/100...\nüîÑ Processing article 60/100...\nüîÑ Processing article 61/100...\nüîÑ Processing article 62/100...\nüîÑ Processing article 63/100...\nüîÑ Processing article 64/100...\nüîÑ Processing article 65/100...\nüîÑ Processing article 66/100...\nüîÑ Processing article 67/100...\nüîÑ Processing article 68/100...\nüîÑ Processing article 69/100...\nüîÑ Processing article 70/100...\nüîÑ Processing article 71/100...\nüîÑ Processing article 72/100...\nüîÑ Processing article 73/100...\nüîÑ Processing article 74/100...\nüîÑ Processing article 75/100...\nüîÑ Processing article 76/100...\nüîÑ Processing article 77/100...\nüîÑ Processing article 78/100...\nüîÑ Processing article 79/100...\nüîÑ Processing article 80/100...\nüîÑ Processing article 81/100...\nüîÑ Processing article 82/100...\nüîÑ Processing article 83/100...\nüîÑ Processing article 84/100...\nüîÑ Processing article 85/100...\nüîÑ Processing article 86/100...\nüîÑ Processing article 87/100...\nüîÑ Processing article 88/100...\nüîÑ Processing article 89/100...\nüîÑ Processing article 90/100...\nüîÑ Processing article 91/100...\nüîÑ Processing article 92/100...\nüîÑ Processing article 93/100...\nüîÑ Processing article 94/100...\nüîÑ Processing article 95/100...\nüîÑ Processing article 96/100...\nüîÑ Processing article 97/100...\nüîÑ Processing article 98/100...\nüîÑ Processing article 99/100...\nüîÑ Processing article 100/100...\n\nüìä AVERAGE ROUGE F1 SCORES OVER FIRST 100 SAMPLES:\nROUGE1: 0.1952\nROUGE2: 0.0322\nROUGEL: 0.1251\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# Use only first 100 samples\n",
        "X_subset = X\n",
        "y_subset = y\n",
        "\n",
        "# Use last 10 from the subset\n",
        "X_test = X_subset\n",
        "y_test = y_subset\n",
        "\n",
        "# Initialize ROUGE scorer\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "avg_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
        "\n",
        "# Generate summaries and calculate scores\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"üîÑ Processing article {i + 1}/{len(X_test)}...\")\n",
        "\n",
        "    summary = summarize_text(\n",
        "        text=X_test[i],\n",
        "        model=model,\n",
        "        source_tokenizer=e_tk,\n",
        "        word_dict=word_dict,\n",
        "        start_id=start_id,\n",
        "        end_id=end_id,\n",
        "        source_max=input_seq_len,\n",
        "        target_max=output_seq_len\n",
        "    )\n",
        "\n",
        "    scores = scorer.score(y_test[i], summary)\n",
        "    for key in scores:\n",
        "        avg_scores[key].append(scores[key].fmeasure)\n",
        "\n",
        "# Compute and print average F1 scores\n",
        "print(\"\\nüìä AVERAGE ROUGE F1 SCORES OVER TEST SAMPLES:\")\n",
        "for key in avg_scores:\n",
        "    mean_f1 = sum(avg_scores[key]) / len(avg_scores[key])\n",
        "    print(f\"{key.upper()}: {mean_f1:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T06:35:57.614436Z",
          "iopub.execute_input": "2025-04-11T06:35:57.615154Z",
          "iopub.status.idle": "2025-04-11T07:04:51.822888Z",
          "shell.execute_reply.started": "2025-04-11T06:35:57.615132Z",
          "shell.execute_reply": "2025-04-11T07:04:51.822184Z"
        },
        "id": "jHME9DwMzykI",
        "outputId": "ee9f5021-e8da-4bba-d9ed-f680ab8fbaab"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üîÑ Processing article 1/879...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1744353358.586204      89 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "üîÑ Processing article 2/879...\nüîÑ Processing article 3/879...\nüîÑ Processing article 4/879...\nüîÑ Processing article 5/879...\nüîÑ Processing article 6/879...\nüîÑ Processing article 7/879...\nüîÑ Processing article 8/879...\nüîÑ Processing article 9/879...\nüîÑ Processing article 10/879...\nüîÑ Processing article 11/879...\nüîÑ Processing article 12/879...\nüîÑ Processing article 13/879...\nüîÑ Processing article 14/879...\nüîÑ Processing article 15/879...\nüîÑ Processing article 16/879...\nüîÑ Processing article 17/879...\nüîÑ Processing article 18/879...\nüîÑ Processing article 19/879...\nüîÑ Processing article 20/879...\nüîÑ Processing article 21/879...\nüîÑ Processing article 22/879...\nüîÑ Processing article 23/879...\nüîÑ Processing article 24/879...\nüîÑ Processing article 25/879...\nüîÑ Processing article 26/879...\nüîÑ Processing article 27/879...\nüîÑ Processing article 28/879...\nüîÑ Processing article 29/879...\nüîÑ Processing article 30/879...\nüîÑ Processing article 31/879...\nüîÑ Processing article 32/879...\nüîÑ Processing article 33/879...\nüîÑ Processing article 34/879...\nüîÑ Processing article 35/879...\nüîÑ Processing article 36/879...\nüîÑ Processing article 37/879...\nüîÑ Processing article 38/879...\nüîÑ Processing article 39/879...\nüîÑ Processing article 40/879...\nüîÑ Processing article 41/879...\nüîÑ Processing article 42/879...\nüîÑ Processing article 43/879...\nüîÑ Processing article 44/879...\nüîÑ Processing article 45/879...\nüîÑ Processing article 46/879...\nüîÑ Processing article 47/879...\nüîÑ Processing article 48/879...\nüîÑ Processing article 49/879...\nüîÑ Processing article 50/879...\nüîÑ Processing article 51/879...\nüîÑ Processing article 52/879...\nüîÑ Processing article 53/879...\nüîÑ Processing article 54/879...\nüîÑ Processing article 55/879...\nüîÑ Processing article 56/879...\nüîÑ Processing article 57/879...\nüîÑ Processing article 58/879...\nüîÑ Processing article 59/879...\nüîÑ Processing article 60/879...\nüîÑ Processing article 61/879...\nüîÑ Processing article 62/879...\nüîÑ Processing article 63/879...\nüîÑ Processing article 64/879...\nüîÑ Processing article 65/879...\nüîÑ Processing article 66/879...\nüîÑ Processing article 67/879...\nüîÑ Processing article 68/879...\nüîÑ Processing article 69/879...\nüîÑ Processing article 70/879...\nüîÑ Processing article 71/879...\nüîÑ Processing article 72/879...\nüîÑ Processing article 73/879...\nüîÑ Processing article 74/879...\nüîÑ Processing article 75/879...\nüîÑ Processing article 76/879...\nüîÑ Processing article 77/879...\nüîÑ Processing article 78/879...\nüîÑ Processing article 79/879...\nüîÑ Processing article 80/879...\nüîÑ Processing article 81/879...\nüîÑ Processing article 82/879...\nüîÑ Processing article 83/879...\nüîÑ Processing article 84/879...\nüîÑ Processing article 85/879...\nüîÑ Processing article 86/879...\nüîÑ Processing article 87/879...\nüîÑ Processing article 88/879...\nüîÑ Processing article 89/879...\nüîÑ Processing article 90/879...\nüîÑ Processing article 91/879...\nüîÑ Processing article 92/879...\nüîÑ Processing article 93/879...\nüîÑ Processing article 94/879...\nüîÑ Processing article 95/879...\nüîÑ Processing article 96/879...\nüîÑ Processing article 97/879...\nüîÑ Processing article 98/879...\nüîÑ Processing article 99/879...\nüîÑ Processing article 100/879...\nüîÑ Processing article 101/879...\nüîÑ Processing article 102/879...\nüîÑ Processing article 103/879...\nüîÑ Processing article 104/879...\nüîÑ Processing article 105/879...\nüîÑ Processing article 106/879...\nüîÑ Processing article 107/879...\nüîÑ Processing article 108/879...\nüîÑ Processing article 109/879...\nüîÑ Processing article 110/879...\nüîÑ Processing article 111/879...\nüîÑ Processing article 112/879...\nüîÑ Processing article 113/879...\nüîÑ Processing article 114/879...\nüîÑ Processing article 115/879...\nüîÑ Processing article 116/879...\nüîÑ Processing article 117/879...\nüîÑ Processing article 118/879...\nüîÑ Processing article 119/879...\nüîÑ Processing article 120/879...\nüîÑ Processing article 121/879...\nüîÑ Processing article 122/879...\nüîÑ Processing article 123/879...\nüîÑ Processing article 124/879...\nüîÑ Processing article 125/879...\nüîÑ Processing article 126/879...\nüîÑ Processing article 127/879...\nüîÑ Processing article 128/879...\nüîÑ Processing article 129/879...\nüîÑ Processing article 130/879...\nüîÑ Processing article 131/879...\nüîÑ Processing article 132/879...\nüîÑ Processing article 133/879...\nüîÑ Processing article 134/879...\nüîÑ Processing article 135/879...\nüîÑ Processing article 136/879...\nüîÑ Processing article 137/879...\nüîÑ Processing article 138/879...\nüîÑ Processing article 139/879...\nüîÑ Processing article 140/879...\nüîÑ Processing article 141/879...\nüîÑ Processing article 142/879...\nüîÑ Processing article 143/879...\nüîÑ Processing article 144/879...\nüîÑ Processing article 145/879...\nüîÑ Processing article 146/879...\nüîÑ Processing article 147/879...\nüîÑ Processing article 148/879...\nüîÑ Processing article 149/879...\nüîÑ Processing article 150/879...\nüîÑ Processing article 151/879...\nüîÑ Processing article 152/879...\nüîÑ Processing article 153/879...\nüîÑ Processing article 154/879...\nüîÑ Processing article 155/879...\nüîÑ Processing article 156/879...\nüîÑ Processing article 157/879...\nüîÑ Processing article 158/879...\nüîÑ Processing article 159/879...\nüîÑ Processing article 160/879...\nüîÑ Processing article 161/879...\nüîÑ Processing article 162/879...\nüîÑ Processing article 163/879...\nüîÑ Processing article 164/879...\nüîÑ Processing article 165/879...\nüîÑ Processing article 166/879...\nüîÑ Processing article 167/879...\nüîÑ Processing article 168/879...\nüîÑ Processing article 169/879...\nüîÑ Processing article 170/879...\nüîÑ Processing article 171/879...\nüîÑ Processing article 172/879...\nüîÑ Processing article 173/879...\nüîÑ Processing article 174/879...\nüîÑ Processing article 175/879...\nüîÑ Processing article 176/879...\nüîÑ Processing article 177/879...\nüîÑ Processing article 178/879...\nüîÑ Processing article 179/879...\nüîÑ Processing article 180/879...\nüîÑ Processing article 181/879...\nüîÑ Processing article 182/879...\nüîÑ Processing article 183/879...\nüîÑ Processing article 184/879...\nüîÑ Processing article 185/879...\nüîÑ Processing article 186/879...\nüîÑ Processing article 187/879...\nüîÑ Processing article 188/879...\nüîÑ Processing article 189/879...\nüîÑ Processing article 190/879...\nüîÑ Processing article 191/879...\nüîÑ Processing article 192/879...\nüîÑ Processing article 193/879...\nüîÑ Processing article 194/879...\nüîÑ Processing article 195/879...\nüîÑ Processing article 196/879...\nüîÑ Processing article 197/879...\nüîÑ Processing article 198/879...\nüîÑ Processing article 199/879...\nüîÑ Processing article 200/879...\nüîÑ Processing article 201/879...\nüîÑ Processing article 202/879...\nüîÑ Processing article 203/879...\nüîÑ Processing article 204/879...\nüîÑ Processing article 205/879...\nüîÑ Processing article 206/879...\nüîÑ Processing article 207/879...\nüîÑ Processing article 208/879...\nüîÑ Processing article 209/879...\nüîÑ Processing article 210/879...\nüîÑ Processing article 211/879...\nüîÑ Processing article 212/879...\nüîÑ Processing article 213/879...\nüîÑ Processing article 214/879...\nüîÑ Processing article 215/879...\nüîÑ Processing article 216/879...\nüîÑ Processing article 217/879...\nüîÑ Processing article 218/879...\nüîÑ Processing article 219/879...\nüîÑ Processing article 220/879...\nüîÑ Processing article 221/879...\nüîÑ Processing article 222/879...\nüîÑ Processing article 223/879...\nüîÑ Processing article 224/879...\nüîÑ Processing article 225/879...\nüîÑ Processing article 226/879...\nüîÑ Processing article 227/879...\nüîÑ Processing article 228/879...\nüîÑ Processing article 229/879...\nüîÑ Processing article 230/879...\nüîÑ Processing article 231/879...\nüîÑ Processing article 232/879...\nüîÑ Processing article 233/879...\nüîÑ Processing article 234/879...\nüîÑ Processing article 235/879...\nüîÑ Processing article 236/879...\nüîÑ Processing article 237/879...\nüîÑ Processing article 238/879...\nüîÑ Processing article 239/879...\nüîÑ Processing article 240/879...\nüîÑ Processing article 241/879...\nüîÑ Processing article 242/879...\nüîÑ Processing article 243/879...\nüîÑ Processing article 244/879...\nüîÑ Processing article 245/879...\nüîÑ Processing article 246/879...\nüîÑ Processing article 247/879...\nüîÑ Processing article 248/879...\nüîÑ Processing article 249/879...\nüîÑ Processing article 250/879...\nüîÑ Processing article 251/879...\nüîÑ Processing article 252/879...\nüîÑ Processing article 253/879...\nüîÑ Processing article 254/879...\nüîÑ Processing article 255/879...\nüîÑ Processing article 256/879...\nüîÑ Processing article 257/879...\nüîÑ Processing article 258/879...\nüîÑ Processing article 259/879...\nüîÑ Processing article 260/879...\nüîÑ Processing article 261/879...\nüîÑ Processing article 262/879...\nüîÑ Processing article 263/879...\nüîÑ Processing article 264/879...\nüîÑ Processing article 265/879...\nüîÑ Processing article 266/879...\nüîÑ Processing article 267/879...\nüîÑ Processing article 268/879...\nüîÑ Processing article 269/879...\nüîÑ Processing article 270/879...\nüîÑ Processing article 271/879...\nüîÑ Processing article 272/879...\nüîÑ Processing article 273/879...\nüîÑ Processing article 274/879...\nüîÑ Processing article 275/879...\nüîÑ Processing article 276/879...\nüîÑ Processing article 277/879...\nüîÑ Processing article 278/879...\nüîÑ Processing article 279/879...\nüîÑ Processing article 280/879...\nüîÑ Processing article 281/879...\nüîÑ Processing article 282/879...\nüîÑ Processing article 283/879...\nüîÑ Processing article 284/879...\nüîÑ Processing article 285/879...\nüîÑ Processing article 286/879...\nüîÑ Processing article 287/879...\nüîÑ Processing article 288/879...\nüîÑ Processing article 289/879...\nüîÑ Processing article 290/879...\nüîÑ Processing article 291/879...\nüîÑ Processing article 292/879...\nüîÑ Processing article 293/879...\nüîÑ Processing article 294/879...\nüîÑ Processing article 295/879...\nüîÑ Processing article 296/879...\nüîÑ Processing article 297/879...\nüîÑ Processing article 298/879...\nüîÑ Processing article 299/879...\nüîÑ Processing article 300/879...\nüîÑ Processing article 301/879...\nüîÑ Processing article 302/879...\nüîÑ Processing article 303/879...\nüîÑ Processing article 304/879...\nüîÑ Processing article 305/879...\nüîÑ Processing article 306/879...\nüîÑ Processing article 307/879...\nüîÑ Processing article 308/879...\nüîÑ Processing article 309/879...\nüîÑ Processing article 310/879...\nüîÑ Processing article 311/879...\nüîÑ Processing article 312/879...\nüîÑ Processing article 313/879...\nüîÑ Processing article 314/879...\nüîÑ Processing article 315/879...\nüîÑ Processing article 316/879...\nüîÑ Processing article 317/879...\nüîÑ Processing article 318/879...\nüîÑ Processing article 319/879...\nüîÑ Processing article 320/879...\nüîÑ Processing article 321/879...\nüîÑ Processing article 322/879...\nüîÑ Processing article 323/879...\nüîÑ Processing article 324/879...\nüîÑ Processing article 325/879...\nüîÑ Processing article 326/879...\nüîÑ Processing article 327/879...\nüîÑ Processing article 328/879...\nüîÑ Processing article 329/879...\nüîÑ Processing article 330/879...\nüîÑ Processing article 331/879...\nüîÑ Processing article 332/879...\nüîÑ Processing article 333/879...\nüîÑ Processing article 334/879...\nüîÑ Processing article 335/879...\nüîÑ Processing article 336/879...\nüîÑ Processing article 337/879...\nüîÑ Processing article 338/879...\nüîÑ Processing article 339/879...\nüîÑ Processing article 340/879...\nüîÑ Processing article 341/879...\nüîÑ Processing article 342/879...\nüîÑ Processing article 343/879...\nüîÑ Processing article 344/879...\nüîÑ Processing article 345/879...\nüîÑ Processing article 346/879...\nüîÑ Processing article 347/879...\nüîÑ Processing article 348/879...\nüîÑ Processing article 349/879...\nüîÑ Processing article 350/879...\nüîÑ Processing article 351/879...\nüîÑ Processing article 352/879...\nüîÑ Processing article 353/879...\nüîÑ Processing article 354/879...\nüîÑ Processing article 355/879...\nüîÑ Processing article 356/879...\nüîÑ Processing article 357/879...\nüîÑ Processing article 358/879...\nüîÑ Processing article 359/879...\nüîÑ Processing article 360/879...\nüîÑ Processing article 361/879...\nüîÑ Processing article 362/879...\nüîÑ Processing article 363/879...\nüîÑ Processing article 364/879...\nüîÑ Processing article 365/879...\nüîÑ Processing article 366/879...\nüîÑ Processing article 367/879...\nüîÑ Processing article 368/879...\nüîÑ Processing article 369/879...\nüîÑ Processing article 370/879...\nüîÑ Processing article 371/879...\nüîÑ Processing article 372/879...\nüîÑ Processing article 373/879...\nüîÑ Processing article 374/879...\nüîÑ Processing article 375/879...\nüîÑ Processing article 376/879...\nüîÑ Processing article 377/879...\nüîÑ Processing article 378/879...\nüîÑ Processing article 379/879...\nüîÑ Processing article 380/879...\nüîÑ Processing article 381/879...\nüîÑ Processing article 382/879...\nüîÑ Processing article 383/879...\nüîÑ Processing article 384/879...\nüîÑ Processing article 385/879...\nüîÑ Processing article 386/879...\nüîÑ Processing article 387/879...\nüîÑ Processing article 388/879...\nüîÑ Processing article 389/879...\nüîÑ Processing article 390/879...\nüîÑ Processing article 391/879...\nüîÑ Processing article 392/879...\nüîÑ Processing article 393/879...\nüîÑ Processing article 394/879...\nüîÑ Processing article 395/879...\nüîÑ Processing article 396/879...\nüîÑ Processing article 397/879...\nüîÑ Processing article 398/879...\nüîÑ Processing article 399/879...\nüîÑ Processing article 400/879...\nüîÑ Processing article 401/879...\nüîÑ Processing article 402/879...\nüîÑ Processing article 403/879...\nüîÑ Processing article 404/879...\nüîÑ Processing article 405/879...\nüîÑ Processing article 406/879...\nüîÑ Processing article 407/879...\nüîÑ Processing article 408/879...\nüîÑ Processing article 409/879...\nüîÑ Processing article 410/879...\nüîÑ Processing article 411/879...\nüîÑ Processing article 412/879...\nüîÑ Processing article 413/879...\nüîÑ Processing article 414/879...\nüîÑ Processing article 415/879...\nüîÑ Processing article 416/879...\nüîÑ Processing article 417/879...\nüîÑ Processing article 418/879...\nüîÑ Processing article 419/879...\nüîÑ Processing article 420/879...\nüîÑ Processing article 421/879...\nüîÑ Processing article 422/879...\nüîÑ Processing article 423/879...\nüîÑ Processing article 424/879...\nüîÑ Processing article 425/879...\nüîÑ Processing article 426/879...\nüîÑ Processing article 427/879...\nüîÑ Processing article 428/879...\nüîÑ Processing article 429/879...\nüîÑ Processing article 430/879...\nüîÑ Processing article 431/879...\nüîÑ Processing article 432/879...\nüîÑ Processing article 433/879...\nüîÑ Processing article 434/879...\nüîÑ Processing article 435/879...\nüîÑ Processing article 436/879...\nüîÑ Processing article 437/879...\nüîÑ Processing article 438/879...\nüîÑ Processing article 439/879...\nüîÑ Processing article 440/879...\nüîÑ Processing article 441/879...\nüîÑ Processing article 442/879...\nüîÑ Processing article 443/879...\nüîÑ Processing article 444/879...\nüîÑ Processing article 445/879...\nüîÑ Processing article 446/879...\nüîÑ Processing article 447/879...\nüîÑ Processing article 448/879...\nüîÑ Processing article 449/879...\nüîÑ Processing article 450/879...\nüîÑ Processing article 451/879...\nüîÑ Processing article 452/879...\nüîÑ Processing article 453/879...\nüîÑ Processing article 454/879...\nüîÑ Processing article 455/879...\nüîÑ Processing article 456/879...\nüîÑ Processing article 457/879...\nüîÑ Processing article 458/879...\nüîÑ Processing article 459/879...\nüîÑ Processing article 460/879...\nüîÑ Processing article 461/879...\nüîÑ Processing article 462/879...\nüîÑ Processing article 463/879...\nüîÑ Processing article 464/879...\nüîÑ Processing article 465/879...\nüîÑ Processing article 466/879...\nüîÑ Processing article 467/879...\nüîÑ Processing article 468/879...\nüîÑ Processing article 469/879...\nüîÑ Processing article 470/879...\nüîÑ Processing article 471/879...\nüîÑ Processing article 472/879...\nüîÑ Processing article 473/879...\nüîÑ Processing article 474/879...\nüîÑ Processing article 475/879...\nüîÑ Processing article 476/879...\nüîÑ Processing article 477/879...\nüîÑ Processing article 478/879...\nüîÑ Processing article 479/879...\nüîÑ Processing article 480/879...\nüîÑ Processing article 481/879...\nüîÑ Processing article 482/879...\nüîÑ Processing article 483/879...\nüîÑ Processing article 484/879...\nüîÑ Processing article 485/879...\nüîÑ Processing article 486/879...\nüîÑ Processing article 487/879...\nüîÑ Processing article 488/879...\nüîÑ Processing article 489/879...\nüîÑ Processing article 490/879...\nüîÑ Processing article 491/879...\nüîÑ Processing article 492/879...\nüîÑ Processing article 493/879...\nüîÑ Processing article 494/879...\nüîÑ Processing article 495/879...\nüîÑ Processing article 496/879...\nüîÑ Processing article 497/879...\nüîÑ Processing article 498/879...\nüîÑ Processing article 499/879...\nüîÑ Processing article 500/879...\nüîÑ Processing article 501/879...\nüîÑ Processing article 502/879...\nüîÑ Processing article 503/879...\nüîÑ Processing article 504/879...\nüîÑ Processing article 505/879...\nüîÑ Processing article 506/879...\nüîÑ Processing article 507/879...\nüîÑ Processing article 508/879...\nüîÑ Processing article 509/879...\nüîÑ Processing article 510/879...\nüîÑ Processing article 511/879...\nüîÑ Processing article 512/879...\nüîÑ Processing article 513/879...\nüîÑ Processing article 514/879...\nüîÑ Processing article 515/879...\nüîÑ Processing article 516/879...\nüîÑ Processing article 517/879...\nüîÑ Processing article 518/879...\nüîÑ Processing article 519/879...\nüîÑ Processing article 520/879...\nüîÑ Processing article 521/879...\nüîÑ Processing article 522/879...\nüîÑ Processing article 523/879...\nüîÑ Processing article 524/879...\nüîÑ Processing article 525/879...\nüîÑ Processing article 526/879...\nüîÑ Processing article 527/879...\nüîÑ Processing article 528/879...\nüîÑ Processing article 529/879...\nüîÑ Processing article 530/879...\nüîÑ Processing article 531/879...\nüîÑ Processing article 532/879...\nüîÑ Processing article 533/879...\nüîÑ Processing article 534/879...\nüîÑ Processing article 535/879...\nüîÑ Processing article 536/879...\nüîÑ Processing article 537/879...\nüîÑ Processing article 538/879...\nüîÑ Processing article 539/879...\nüîÑ Processing article 540/879...\nüîÑ Processing article 541/879...\nüîÑ Processing article 542/879...\nüîÑ Processing article 543/879...\nüîÑ Processing article 544/879...\nüîÑ Processing article 545/879...\nüîÑ Processing article 546/879...\nüîÑ Processing article 547/879...\nüîÑ Processing article 548/879...\nüîÑ Processing article 549/879...\nüîÑ Processing article 550/879...\nüîÑ Processing article 551/879...\nüîÑ Processing article 552/879...\nüîÑ Processing article 553/879...\nüîÑ Processing article 554/879...\nüîÑ Processing article 555/879...\nüîÑ Processing article 556/879...\nüîÑ Processing article 557/879...\nüîÑ Processing article 558/879...\nüîÑ Processing article 559/879...\nüîÑ Processing article 560/879...\nüîÑ Processing article 561/879...\nüîÑ Processing article 562/879...\nüîÑ Processing article 563/879...\nüîÑ Processing article 564/879...\nüîÑ Processing article 565/879...\nüîÑ Processing article 566/879...\nüîÑ Processing article 567/879...\nüîÑ Processing article 568/879...\nüîÑ Processing article 569/879...\nüîÑ Processing article 570/879...\nüîÑ Processing article 571/879...\nüîÑ Processing article 572/879...\nüîÑ Processing article 573/879...\nüîÑ Processing article 574/879...\nüîÑ Processing article 575/879...\nüîÑ Processing article 576/879...\nüîÑ Processing article 577/879...\nüîÑ Processing article 578/879...\nüîÑ Processing article 579/879...\nüîÑ Processing article 580/879...\nüîÑ Processing article 581/879...\nüîÑ Processing article 582/879...\nüîÑ Processing article 583/879...\nüîÑ Processing article 584/879...\nüîÑ Processing article 585/879...\nüîÑ Processing article 586/879...\nüîÑ Processing article 587/879...\nüîÑ Processing article 588/879...\nüîÑ Processing article 589/879...\nüîÑ Processing article 590/879...\nüîÑ Processing article 591/879...\nüîÑ Processing article 592/879...\nüîÑ Processing article 593/879...\nüîÑ Processing article 594/879...\nüîÑ Processing article 595/879...\nüîÑ Processing article 596/879...\nüîÑ Processing article 597/879...\nüîÑ Processing article 598/879...\nüîÑ Processing article 599/879...\nüîÑ Processing article 600/879...\nüîÑ Processing article 601/879...\nüîÑ Processing article 602/879...\nüîÑ Processing article 603/879...\nüîÑ Processing article 604/879...\nüîÑ Processing article 605/879...\nüîÑ Processing article 606/879...\nüîÑ Processing article 607/879...\nüîÑ Processing article 608/879...\nüîÑ Processing article 609/879...\nüîÑ Processing article 610/879...\nüîÑ Processing article 611/879...\nüîÑ Processing article 612/879...\nüîÑ Processing article 613/879...\nüîÑ Processing article 614/879...\nüîÑ Processing article 615/879...\nüîÑ Processing article 616/879...\nüîÑ Processing article 617/879...\nüîÑ Processing article 618/879...\nüîÑ Processing article 619/879...\nüîÑ Processing article 620/879...\nüîÑ Processing article 621/879...\nüîÑ Processing article 622/879...\nüîÑ Processing article 623/879...\nüîÑ Processing article 624/879...\nüîÑ Processing article 625/879...\nüîÑ Processing article 626/879...\nüîÑ Processing article 627/879...\nüîÑ Processing article 628/879...\nüîÑ Processing article 629/879...\nüîÑ Processing article 630/879...\nüîÑ Processing article 631/879...\nüîÑ Processing article 632/879...\nüîÑ Processing article 633/879...\nüîÑ Processing article 634/879...\nüîÑ Processing article 635/879...\nüîÑ Processing article 636/879...\nüîÑ Processing article 637/879...\nüîÑ Processing article 638/879...\nüîÑ Processing article 639/879...\nüîÑ Processing article 640/879...\nüîÑ Processing article 641/879...\nüîÑ Processing article 642/879...\nüîÑ Processing article 643/879...\nüîÑ Processing article 644/879...\nüîÑ Processing article 645/879...\nüîÑ Processing article 646/879...\nüîÑ Processing article 647/879...\nüîÑ Processing article 648/879...\nüîÑ Processing article 649/879...\nüîÑ Processing article 650/879...\nüîÑ Processing article 651/879...\nüîÑ Processing article 652/879...\nüîÑ Processing article 653/879...\nüîÑ Processing article 654/879...\nüîÑ Processing article 655/879...\nüîÑ Processing article 656/879...\nüîÑ Processing article 657/879...\nüîÑ Processing article 658/879...\nüîÑ Processing article 659/879...\nüîÑ Processing article 660/879...\nüîÑ Processing article 661/879...\nüîÑ Processing article 662/879...\nüîÑ Processing article 663/879...\nüîÑ Processing article 664/879...\nüîÑ Processing article 665/879...\nüîÑ Processing article 666/879...\nüîÑ Processing article 667/879...\nüîÑ Processing article 668/879...\nüîÑ Processing article 669/879...\nüîÑ Processing article 670/879...\nüîÑ Processing article 671/879...\nüîÑ Processing article 672/879...\nüîÑ Processing article 673/879...\nüîÑ Processing article 674/879...\nüîÑ Processing article 675/879...\nüîÑ Processing article 676/879...\nüîÑ Processing article 677/879...\nüîÑ Processing article 678/879...\nüîÑ Processing article 679/879...\nüîÑ Processing article 680/879...\nüîÑ Processing article 681/879...\nüîÑ Processing article 682/879...\nüîÑ Processing article 683/879...\nüîÑ Processing article 684/879...\nüîÑ Processing article 685/879...\nüîÑ Processing article 686/879...\nüîÑ Processing article 687/879...\nüîÑ Processing article 688/879...\nüîÑ Processing article 689/879...\nüîÑ Processing article 690/879...\nüîÑ Processing article 691/879...\nüîÑ Processing article 692/879...\nüîÑ Processing article 693/879...\nüîÑ Processing article 694/879...\nüîÑ Processing article 695/879...\nüîÑ Processing article 696/879...\nüîÑ Processing article 697/879...\nüîÑ Processing article 698/879...\nüîÑ Processing article 699/879...\nüîÑ Processing article 700/879...\nüîÑ Processing article 701/879...\nüîÑ Processing article 702/879...\nüîÑ Processing article 703/879...\nüîÑ Processing article 704/879...\nüîÑ Processing article 705/879...\nüîÑ Processing article 706/879...\nüîÑ Processing article 707/879...\nüîÑ Processing article 708/879...\nüîÑ Processing article 709/879...\nüîÑ Processing article 710/879...\nüîÑ Processing article 711/879...\nüîÑ Processing article 712/879...\nüîÑ Processing article 713/879...\nüîÑ Processing article 714/879...\nüîÑ Processing article 715/879...\nüîÑ Processing article 716/879...\nüîÑ Processing article 717/879...\nüîÑ Processing article 718/879...\nüîÑ Processing article 719/879...\nüîÑ Processing article 720/879...\nüîÑ Processing article 721/879...\nüîÑ Processing article 722/879...\nüîÑ Processing article 723/879...\nüîÑ Processing article 724/879...\nüîÑ Processing article 725/879...\nüîÑ Processing article 726/879...\nüîÑ Processing article 727/879...\nüîÑ Processing article 728/879...\nüîÑ Processing article 729/879...\nüîÑ Processing article 730/879...\nüîÑ Processing article 731/879...\nüîÑ Processing article 732/879...\nüîÑ Processing article 733/879...\nüîÑ Processing article 734/879...\nüîÑ Processing article 735/879...\nüîÑ Processing article 736/879...\nüîÑ Processing article 737/879...\nüîÑ Processing article 738/879...\nüîÑ Processing article 739/879...\nüîÑ Processing article 740/879...\nüîÑ Processing article 741/879...\nüîÑ Processing article 742/879...\nüîÑ Processing article 743/879...\nüîÑ Processing article 744/879...\nüîÑ Processing article 745/879...\nüîÑ Processing article 746/879...\nüîÑ Processing article 747/879...\nüîÑ Processing article 748/879...\nüîÑ Processing article 749/879...\nüîÑ Processing article 750/879...\nüîÑ Processing article 751/879...\nüîÑ Processing article 752/879...\nüîÑ Processing article 753/879...\nüîÑ Processing article 754/879...\nüîÑ Processing article 755/879...\nüîÑ Processing article 756/879...\nüîÑ Processing article 757/879...\nüîÑ Processing article 758/879...\nüîÑ Processing article 759/879...\nüîÑ Processing article 760/879...\nüîÑ Processing article 761/879...\nüîÑ Processing article 762/879...\nüîÑ Processing article 763/879...\nüîÑ Processing article 764/879...\nüîÑ Processing article 765/879...\nüîÑ Processing article 766/879...\nüîÑ Processing article 767/879...\nüîÑ Processing article 768/879...\nüîÑ Processing article 769/879...\nüîÑ Processing article 770/879...\nüîÑ Processing article 771/879...\nüîÑ Processing article 772/879...\nüîÑ Processing article 773/879...\nüîÑ Processing article 774/879...\nüîÑ Processing article 775/879...\nüîÑ Processing article 776/879...\nüîÑ Processing article 777/879...\nüîÑ Processing article 778/879...\nüîÑ Processing article 779/879...\nüîÑ Processing article 780/879...\nüîÑ Processing article 781/879...\nüîÑ Processing article 782/879...\nüîÑ Processing article 783/879...\nüîÑ Processing article 784/879...\nüîÑ Processing article 785/879...\nüîÑ Processing article 786/879...\nüîÑ Processing article 787/879...\nüîÑ Processing article 788/879...\nüîÑ Processing article 789/879...\nüîÑ Processing article 790/879...\nüîÑ Processing article 791/879...\nüîÑ Processing article 792/879...\nüîÑ Processing article 793/879...\nüîÑ Processing article 794/879...\nüîÑ Processing article 795/879...\nüîÑ Processing article 796/879...\nüîÑ Processing article 797/879...\nüîÑ Processing article 798/879...\nüîÑ Processing article 799/879...\nüîÑ Processing article 800/879...\nüîÑ Processing article 801/879...\nüîÑ Processing article 802/879...\nüîÑ Processing article 803/879...\nüîÑ Processing article 804/879...\nüîÑ Processing article 805/879...\nüîÑ Processing article 806/879...\nüîÑ Processing article 807/879...\nüîÑ Processing article 808/879...\nüîÑ Processing article 809/879...\nüîÑ Processing article 810/879...\nüîÑ Processing article 811/879...\nüîÑ Processing article 812/879...\nüîÑ Processing article 813/879...\nüîÑ Processing article 814/879...\nüîÑ Processing article 815/879...\nüîÑ Processing article 816/879...\nüîÑ Processing article 817/879...\nüîÑ Processing article 818/879...\nüîÑ Processing article 819/879...\nüîÑ Processing article 820/879...\nüîÑ Processing article 821/879...\nüîÑ Processing article 822/879...\nüîÑ Processing article 823/879...\nüîÑ Processing article 824/879...\nüîÑ Processing article 825/879...\nüîÑ Processing article 826/879...\nüîÑ Processing article 827/879...\nüîÑ Processing article 828/879...\nüîÑ Processing article 829/879...\nüîÑ Processing article 830/879...\nüîÑ Processing article 831/879...\nüîÑ Processing article 832/879...\nüîÑ Processing article 833/879...\nüîÑ Processing article 834/879...\nüîÑ Processing article 835/879...\nüîÑ Processing article 836/879...\nüîÑ Processing article 837/879...\nüîÑ Processing article 838/879...\nüîÑ Processing article 839/879...\nüîÑ Processing article 840/879...\nüîÑ Processing article 841/879...\nüîÑ Processing article 842/879...\nüîÑ Processing article 843/879...\nüîÑ Processing article 844/879...\nüîÑ Processing article 845/879...\nüîÑ Processing article 846/879...\nüîÑ Processing article 847/879...\nüîÑ Processing article 848/879...\nüîÑ Processing article 849/879...\nüîÑ Processing article 850/879...\nüîÑ Processing article 851/879...\nüîÑ Processing article 852/879...\nüîÑ Processing article 853/879...\nüîÑ Processing article 854/879...\nüîÑ Processing article 855/879...\nüîÑ Processing article 856/879...\nüîÑ Processing article 857/879...\nüîÑ Processing article 858/879...\nüîÑ Processing article 859/879...\nüîÑ Processing article 860/879...\nüîÑ Processing article 861/879...\nüîÑ Processing article 862/879...\nüîÑ Processing article 863/879...\nüîÑ Processing article 864/879...\nüîÑ Processing article 865/879...\nüîÑ Processing article 866/879...\nüîÑ Processing article 867/879...\nüîÑ Processing article 868/879...\nüîÑ Processing article 869/879...\nüîÑ Processing article 870/879...\nüîÑ Processing article 871/879...\nüîÑ Processing article 872/879...\nüîÑ Processing article 873/879...\nüîÑ Processing article 874/879...\nüîÑ Processing article 875/879...\nüîÑ Processing article 876/879...\nüîÑ Processing article 877/879...\nüîÑ Processing article 878/879...\nüîÑ Processing article 879/879...\n\nüìä AVERAGE ROUGE F1 SCORES OVER TEST SAMPLES:\nROUGE1: 0.1954\nROUGE2: 0.0325\nROUGEL: 0.1239\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h2 style='text-align:center;'>Observations</h2>\n",
        "\n",
        "+ As part of our course project, we implemented an attention-based Seq2Seq model for text summarization and evaluated it using ROUGE metrics.\n",
        "+ We initially experimented with a baseline model **without attention**, but it produced poor results both qualitatively and quantitatively. Due to its limitations, we decided not to pursue it further.\n",
        "+ In contrast, the attention-based model generated more coherent and contextually relevant summaries, despite occasional word repetitions or mid-sentence mix-ups.\n",
        "+ Although the model was more complex and took longer to train, the performance gains justified the added overhead.\n",
        "+ The ROUGE evaluation metrics clearly reflected the model‚Äôs effectiveness:\n",
        "\n",
        "  üìä **AVERAGE ROUGE F1 SCORES OVER FIRST 100 SAMPLES**:  \n",
        "  ‚Ä£ **ROUGE-1**: 0.1952  \n",
        "  ‚Ä£ **ROUGE-2**: 0.0322  \n",
        "  ‚Ä£ **ROUGE-L**: 0.1251  \n",
        "\n",
        "  üìä **AVERAGE ROUGE F1 SCORES OVER TEST SAMPLES** (after filtering):  \n",
        "  ‚Ä£ **ROUGE-1**: 0.1954  \n",
        "  ‚Ä£ **ROUGE-2**: 0.0325  \n",
        "  ‚Ä£ **ROUGE-L**: 0.1239  \n",
        "\n",
        "+ These results confirm the value of incorporating attention in sequence modeling and pave the way for exploring more advanced models like Transformers in future work.\n"
      ],
      "metadata": {
        "id": "9BEnZs1TzykI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr><br>\n",
        "<h3 style='text-align:center;'><strong>References</strong></h3>\n",
        "<p style='text-align:center;'>\n",
        "<br>\n",
        "    \n",
        "Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. https://arxiv.org/abs/1409.3215\n",
        "\n",
        "Attention Mechanism:\n",
        "\n",
        "Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. 1 https://arxiv.org/pdf/1409.0473  \n",
        "\n",
        "Luong, M.-T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. https://aclanthology.org/D15-1166/\n",
        "\n",
        "\n",
        "<ul>\n",
        "    <li>\n",
        "        <b>Original Paper for Teacher Forcing:</b>\n",
        "        <ul>\n",
        "            <li>Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. \"Sequence to sequence learning with neural networks.\" Advances in neural information processing systems 27 (2014).<br></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li>\n",
        "        <b>Review Papers:</b>\n",
        "        <ul>\n",
        "            <li>Wu, Yonghui, et al. \"Google's neural machine translation system: Bridging the gap between human and machine translation.\" arXiv preprint arXiv:1609.08144 (2016).</li>\n",
        "            <li>Young, Tom, et al. \"Recent trends in neural machine translation.\" arXiv preprint arXiv:1703.01619 (2017).<br></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li>\n",
        "        <b>Tutorials and Blog Posts:</b>\n",
        "        <ul>\n",
        "            <li><b>Understanding Teacher Forcing in Seq2Seq Models</b> by Lilian Weng: <a href=\"https://lilianweng.github.io/\">https://lilianweng.github.io/</a></li>\n",
        "            <li><b>Seq2Seq Tutorial with Neural Networks</b> by PyTorch: <a href=\"https://pytorch.org/tutorials/\">https://pytorch.org/tutorials/</a><br></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "    <li>\n",
        "        <b>Research Papers Exploring Alternatives to Teacher Forcing:</b>\n",
        "        <ul>\n",
        "            <li><b>Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks</b> by Samy Bengio et al.: <a href=\"https://arxiv.org/abs/1506.03099\">https://arxiv.org/abs/1506.03099</a></li>\n",
        "            <li><b>Improved Training of Sequence to Sequence Models</b> by Minh-Thang Luong et al.: <a href=\"https://research.google/pubs/sequence-to-sequence-learning-with-neural-networks/\">https://research.google/pubs/sequence-to-sequence-learning-with-neural-networks/</a><br></li>\n",
        "        </ul>\n",
        "    </li>\n",
        "</ul>\n",
        "    \n",
        "</p>"
      ],
      "metadata": {
        "id": "MHKPMcvIzykI"
      }
    }
  ]
}